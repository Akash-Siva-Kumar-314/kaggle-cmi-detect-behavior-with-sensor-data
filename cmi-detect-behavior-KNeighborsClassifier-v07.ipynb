{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b0e49de-0d7e-45b0-bf83-1b1ade16889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bea1658-7658-412a-8074-3f5193ab1940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here first row from test data is taken and prediction returned, \n",
    "# the second time the funtion is called the second row of test data is taken and prediction returned and so on.\n",
    "\n",
    "# Global counter to keep track of which test row to use\n",
    "current_test_index = 0\n",
    "\n",
    "# Using a funtion to contain our code snippet\n",
    "def predict(): \n",
    "    global current_test_index\n",
    "\n",
    "    # Loading the CSV file\n",
    "    file_path = 'D:/kaggle-cmi-detect-behavior-with-sensor-data/cmi-detect-behavior-with-sensor-data/train.csv'\n",
    "\n",
    "    # Reading the CSV file\n",
    "    df_original_data = pd.read_csv(file_path)\n",
    "\n",
    "    # Display the first few rows of the dataframe, we will be doing this as checking step every step along the way\n",
    "    #df_original_data.head()\n",
    "\n",
    "    # Checking number of null values in each column\n",
    "    #df_original_data.isnull().sum()\n",
    "\n",
    "    # Defining feature and target\n",
    "    A = df_original_data.iloc[:, 9:].values\n",
    "    b = df_original_data.iloc[:, 8].values\n",
    "\n",
    "    #print(A)\n",
    "    #print(b)\n",
    "\n",
    "    # Now the feature column has some null values - imputing them with a constant value Zero    \n",
    "    # Replace NaNs with 0\n",
    "    A = df_original_data.iloc[:, 9:].values\n",
    "    A = np.nan_to_num(A, nan=0)\n",
    "    #print(A[:5])  # Display first 5 rows\n",
    "\n",
    "    # Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    A_train_s = sc.fit_transform(A)\n",
    "\n",
    "    # Instead of test train split, using whole of the data to train our model.\n",
    "\n",
    "    # Fitting KNN to the training set\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(A_train_s, b)\n",
    "\n",
    "    # Importing the testing data \n",
    "\n",
    "    # Loading the CSV file\n",
    "    file_path_test = 'D:/kaggle-cmi-detect-behavior-with-sensor-data/cmi-detect-behavior-with-sensor-data/test.csv'\n",
    "    \n",
    "    # Reading the CSV file\n",
    "    df_original_test_data = pd.read_csv(file_path_test)\n",
    "\n",
    "    # Display the first few rows of the dataframe, we will be doing this as checking step every step along the way\n",
    "    #df_original_test_data.head()\n",
    "\n",
    "    # Only taking needed columns from test data, and the needed row\n",
    "    original_test_data = df_original_test_data.iloc[current_test_index, 4:].values\n",
    "    current_test_index += 1 # To update the row value, when the funtion is called next time\n",
    "    print(current_test_index)\n",
    "    # Reshape is done coz above code gives a 1D shape while the input for next is a 2D shape, just a small tweak.\n",
    "    original_test_data = original_test_data.reshape(1, -1)\n",
    "    #print(original_test_data)\n",
    "\n",
    "    # Predicting the test set - results\n",
    "    y_pred = classifier.predict(original_test_data)\n",
    "    #print(y_pred)\n",
    "\n",
    "    y_pred_string = str(y_pred[0]) # Converting the return value to a string.\n",
    "\n",
    "    return y_pred_string\n",
    "\n",
    "    # ~ End of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2636f32e-acee-4ed3-bf4d-54eb2d3b8611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Wave hello'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0764e942-1e5d-4645-afbc-d0877438ee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Wave hello'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39627b44-6e03-4259-b3c5-8cff5d1c50a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Wave hello'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d50459b-5b75-4483-b3cb-9af0b5db79ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Wave hello'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5fa9596-c8e7-45cc-a6b6-6bbde6bffbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Wave hello'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4c6da6c-0c7e-4421-bb24-f80614fecfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Prediction 1: Wave hello\n",
      "7\n",
      "Prediction 2: Wave hello\n",
      "8\n",
      "Prediction 3: Wave hello\n",
      "9\n",
      "Prediction 4: Wave hello\n",
      "10\n",
      "Prediction 5: Cheek - pinch skin\n",
      "11\n",
      "Prediction 6: Wave hello\n",
      "12\n",
      "Prediction 7: Wave hello\n",
      "13\n",
      "Prediction 8: Wave hello\n",
      "14\n",
      "Prediction 9: Wave hello\n",
      "15\n",
      "Prediction 10: Cheek - pinch skin\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    result = predict()\n",
    "    print(f\"Prediction {_ + 1}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9abb01-4a59-4690-b7a8-97aee9ca23ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
